
<!DOCTYPE html>
<html>
  <head>
    <title></title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [["$","$"]]}
      });
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    </script>
   <script type="text/javascript"
       src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full">
   </script>
   <script async="async" data-cfasync="false" src="//pl22489825.profitablegatecpm.com/d84f574876e65b2d8f0c7bae784c22b3/invoke.js"></script>

   <link rel="stylesheet" type="text/css" media="screen" href="https://burakbayramli.github.io/css/style.css">
  </head>
    <body>
      <div id="header_wrap" class="outer">
        <header class="inner">
          <h1 id="project_title">
            <a href="https://burakbayramli.github.io" style="text-decoration:none; color:inherit;">dersblog</a>
          </h1>
          <h2 id="project_tagline"></h2>          
        </header>
      </div>
      <div id="main_content_wrap" class="outer">        
        <section id="main_content" class="inner">
        <h1></h1>
<h1>Dikkat (Attention) Modelleri, YSA</h1>

<div class="codehilite">
<pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="kn">import</span> <span class="n">read_csv</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span><span class="o">,</span><span class="w"> </span><span class="nn">keras</span><span class="o">,</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Layer</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">keras.backend</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">K</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">SimpleRNN</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">keras.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">keras.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span>

<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Keras&#39;</span><span class="p">,</span><span class="n">keras</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;TF&#39;</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>

<span class="c1"># Prepare data</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_fib_seq</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">scale_data</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="c1"># Get the Fibonacci sequence</span>
    <span class="n">seq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">fib_n1</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">fib_n</span> <span class="o">=</span> <span class="mf">1.0</span> 
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">seq</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">fib_n1</span> <span class="o">+</span> <span class="n">fib_n</span>
            <span class="n">fib_n1</span> <span class="o">=</span> <span class="n">fib_n</span>
            <span class="n">fib_n</span> <span class="o">=</span> <span class="n">seq</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> 
    <span class="n">scaler</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">scale_data</span><span class="p">:</span>
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">seq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">seq</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>        
    <span class="k">return</span> <span class="n">seq</span><span class="p">,</span> <span class="n">scaler</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_fib_XY</span><span class="p">(</span><span class="n">total_fib_numbers</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">,</span> <span class="n">train_percent</span><span class="p">,</span> <span class="n">scale_data</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">dat</span><span class="p">,</span> <span class="n">scaler</span> <span class="o">=</span> <span class="n">get_fib_seq</span><span class="p">(</span><span class="n">total_fib_numbers</span><span class="p">,</span> <span class="n">scale_data</span><span class="p">)</span>    
    <span class="n">Y_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">time_steps</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dat</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">dat</span><span class="p">[</span><span class="n">Y_ind</span><span class="p">]</span>
    <span class="n">rows_x</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">dat</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">rows_x</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">time_steps</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">temp</span> <span class="o">=</span> <span class="n">dat</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">rows_x</span><span class="o">+</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">temp</span><span class="p">))</span>
    <span class="c1"># random permutation with fixed seed   </span>
    <span class="n">rand</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">rand</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">rows_x</span><span class="p">)</span>
    <span class="n">split</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_percent</span><span class="o">*</span><span class="n">rows_x</span><span class="p">)</span>
    <span class="n">train_ind</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">split</span><span class="p">]</span>
    <span class="n">test_ind</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="n">split</span><span class="p">:]</span>
    <span class="n">trainX</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_ind</span><span class="p">]</span>
    <span class="n">trainY</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">train_ind</span><span class="p">]</span>
    <span class="n">testX</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">test_ind</span><span class="p">]</span>
    <span class="n">testY</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">test_ind</span><span class="p">]</span>
    <span class="n">trainX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainX</span><span class="p">),</span> <span class="n">time_steps</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>    
    <span class="n">testX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testX</span><span class="p">),</span> <span class="n">time_steps</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testY</span><span class="p">,</span> <span class="n">scaler</span>

<span class="c1"># Set up parameters</span>
<span class="n">time_steps</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">hidden_units</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">30</span>

<span class="c1"># Create a traditional RNN network</span>
<span class="k">def</span><span class="w"> </span><span class="nf">create_RNN</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dense_units</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">activation</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">SimpleRNN</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">dense_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">model_RNN</span> <span class="o">=</span> <span class="n">create_RNN</span><span class="p">(</span><span class="n">hidden_units</span><span class="o">=</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dense_units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">time_steps</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> 
                   <span class="n">activation</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="s1">&#39;tanh&#39;</span><span class="p">])</span>

<span class="c1"># Generate the dataset for the network</span>
<span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testY</span><span class="p">,</span> <span class="n">scaler</span>  <span class="o">=</span> <span class="n">get_fib_XY</span><span class="p">(</span><span class="mi">1200</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">)</span>
<span class="c1"># Train the network</span>
<span class="n">model_RNN</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>


<span class="c1"># Evalute model</span>
<span class="n">train_mse</span> <span class="o">=</span> <span class="n">model_RNN</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">)</span>
<span class="n">test_mse</span> <span class="o">=</span> <span class="n">model_RNN</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testY</span><span class="p">)</span>

<span class="c1"># Print error</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train set MSE Without Attn = &quot;</span><span class="p">,</span> <span class="n">train_mse</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set MSE Without Attn = &quot;</span><span class="p">,</span> <span class="n">test_mse</span><span class="p">)</span>


<span class="c1"># Add attention layer to the deep learning network</span>
<span class="k">class</span><span class="w"> </span><span class="nc">attention</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">attention</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">input_shape</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;attention_weight&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="mi">1</span><span class="p">),</span> 
                               <span class="n">initializer</span><span class="o">=</span><span class="s1">&#39;random_normal&#39;</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;attention_bias&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="mi">1</span><span class="p">),</span> 
                               <span class="n">initializer</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>        
        <span class="nb">super</span><span class="p">(</span><span class="n">attention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="c1"># Alignment scores. Pass them through tanh function</span>
        <span class="n">e</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
        <span class="c1"># Remove dimension of size 1</span>
        <span class="n">e</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>   
        <span class="c1"># Compute the weights</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="c1"># Reshape to tensorFlow format</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Compute the context vector</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">alpha</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">context</span>

<span class="k">def</span><span class="w"> </span><span class="nf">create_RNN_with_attention</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dense_units</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">activation</span><span class="p">):</span>
    <span class="n">x</span><span class="o">=</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="n">RNN_layer</span> <span class="o">=</span> <span class="n">SimpleRNN</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">attention_layer</span> <span class="o">=</span> <span class="n">attention</span><span class="p">()(</span><span class="n">RNN_layer</span><span class="p">)</span>
    <span class="n">outputs</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">dense_units</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)(</span><span class="n">attention_layer</span><span class="p">)</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">outputs</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>    
    <span class="k">return</span> <span class="n">model</span>    

<span class="c1"># Create the model with attention, train and evaluate</span>
<span class="n">model_attention</span> <span class="o">=</span> <span class="n">create_RNN_with_attention</span><span class="p">(</span><span class="n">hidden_units</span><span class="o">=</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dense_units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                                  <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">time_steps</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">)</span>
<span class="n">model_attention</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>    


<span class="n">model_attention</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Evalute model</span>
<span class="n">train_mse_attn</span> <span class="o">=</span> <span class="n">model_attention</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">)</span>
<span class="n">test_mse_attn</span> <span class="o">=</span> <span class="n">model_attention</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testY</span><span class="p">)</span>

<span class="c1"># Print error</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train set MSE with attention = &quot;</span><span class="p">,</span> <span class="n">train_mse_attn</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set MSE with attention = &quot;</span><span class="p">,</span> <span class="n">test_mse_attn</span><span class="p">)</span>
</code></pre>
</div>

<pre><code>Keras 2.15.0
TF 2.15.1
Epoch 1/30
826/826 - 4s - loss: 0.0035 - 4s/epoch - 4ms/step
Epoch 2/30
826/826 - 3s - loss: 0.0034 - 3s/epoch - 3ms/step
Epoch 3/30
...
Epoch 26/30
826/826 - 3s - loss: 0.0010 - 3s/epoch - 3ms/step
Epoch 27/30
826/826 - 3s - loss: 9.4093e-04 - 3s/epoch - 3ms/step
Epoch 28/30
826/826 - 3s - loss: 8.6900e-04 - 3s/epoch - 3ms/step
Epoch 29/30
826/826 - 3s - loss: 7.9342e-04 - 3s/epoch - 3ms/step
Epoch 30/30
826/826 - 3s - loss: 7.1211e-04 - 3s/epoch - 3ms/step
1/26 [&gt;.............................] - ETA: 6s - loss: 2.7926e-04
22/26 [========================&gt;.....] - ETA: 0s - loss: 7.3791e-04
26/26 [==============================] - 0s 2ms/step - loss: 6.2892e-04
1/12 [=&gt;............................] - ETA: 0s - loss: 7.3267e-04
12/12 [==============================] - 0s 2ms/step - loss: 5.3967e-04
Train set MSE Without Attn =  0.0006289228913374245
Test set MSE Without Attn =  0.0005396747146733105
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 20, 1)]           0         

 simple_rnn_1 (SimpleRNN)    (None, 20, 2)             8         

 attention (attention)       (None, 2)                 22        

 dense_1 (Dense)             (None, 1)                 3         

=================================================================
Total params: 33 (132.00 Byte)
Trainable params: 33 (132.00 Byte)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
Epoch 1/30
826/826 - 4s - loss: 0.0011 - 4s/epoch - 5ms/step
Epoch 2/30
826/826 - 3s - loss: 0.0011 - 3s/epoch - 4ms/step
Epoch 3/30
826/826 - 3s - loss: 0.0011 - 3s/epoch - 4ms/step
Epoch 4/30
826/826 - 3s - loss: 0.0010 - 3s/epoch - 3ms/step
Epoch 5/30
826/826 - 3s - loss: 9.8559e-04 - 3s/epoch - 3ms/step
Epoch 6/30
826/826 - 3s - loss: 9.4220e-04 - 3s/epoch - 4ms/step
Epoch 7/30
826/826 - 3s - loss: 8.8950e-04 - 3s/epoch - 4ms/step
Epoch 8/30
826/826 - 3s - loss: 8.5065e-04 - 3s/epoch - 4ms/step
Epoch 9/30
..
Epoch 30/30
826/826 - 3s - loss: 6.8983e-05 - 3s/epoch - 3ms/step

 1/26 [&gt;.............................] - ETA: 5s - loss: 4.8165e-07
21/26 [=======================&gt;......] - ETA: 0s - loss: 6.9184e-05
26/26 [==============================] - 0s 3ms/step - loss: 5.6285e-05

 1/12 [=&gt;............................] - ETA: 0s - loss: 6.3000e-06
12/12 [==============================] - 0s 3ms/step - loss: 5.9010e-07
Train set MSE with attention =  5.628508370136842e-05
Test set MSE with attention =  5.901009672015789e-07
</code></pre>

<p>0.00002662211591
0.0008260479662567377</p>

<p>Kaynaklar</p>

<p>[1] https://machinelearningmastery.com/adding-a-custom-attention-layer-to-recurrent-neural-network-in-keras/</p>

          <div id="container-d84f574876e65b2d8f0c7bae784c22b3"></div>

          <br/><a href="../index.html">YukarÄ±</a>
        </section>          
      </div>
    </body>
</html>
