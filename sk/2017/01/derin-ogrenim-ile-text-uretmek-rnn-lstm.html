
<!DOCTYPE html>
<html>
  <head>
    <title></title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [["$","$"]]}
      });
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    </script>
   <script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full">
   </script>
   <link rel="stylesheet" type="text/css" media="screen" href="https://burakbayramli.github.io/css/style.css">
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1548953794786292"
          crossorigin="anonymous"></script>  
  </head>
    <body>
      <div id="header_wrap" class="outer">
        <header class="inner">
          <h1 id="project_title">
            <a href="https://burakbayramli.github.io" style="text-decoration:none; color:inherit;">dersblog</a>
          </h1>
          <h2 id="project_tagline"></h2>          
        </header>
      </div>
      <div id="main_content_wrap" class="outer">        
        <section id="main_content" class="inner">
        <h1></h1>
<h1>Derin Öğrenim ile Text Üretmek, RNN, LSTM</h1>

<p>Derin Öğrenim her yerde; yapay sinir ağları sağlam bir dönüş yaptılar,
ve ardı ardına ilerlemeler, ve ilginç kullanımlar haberleri
görülebiliyor. Bunlardan biri A. Karpathy'nin Kendini Tekrarlayan
Yapay Sinir Ağları (Recurrent Neural Network, -RNN-) hakkında
yazdıkları. Arkadaş Shakespeare'in uzun bir oyununu RNN'e okutup sonra
bu ağdan Shakespeare ürettirmiş. Sonuçlar fena değil.</p>

<p>Öteki yandan alttaki Y. Goldberg adlı birisi sadece önceki N
karakterden sonra her karakterin kaç kere geldiğini "sayarak" ve
frekansları kullanarak metin üretmiş. Burada derin öğrenim filan yok,
sadece basit sayım var. Sonuçlar onda da iyi. Ama nasıl oldu bu iş?
Derin YSA hiçbir iş yapmıyor mu yani? Fakat Goldberg'in dediği gibi
aslında RNN, LSTM gibi derin modelleri daha farklı bir şey
yapıyorlar. Shakespeare örneğinde her iki yaklaşım da Shakespeare'imsi
bir şeyler üretiyor, fakat RNN, LSTM yaklaşımında bazı gramer yapıları
öğrenilmeye başlanıyor.</p>

<p>Mesela parantez açıp bir blok sonra parantez kapamak frekans modelleri
için zor, fakat DO bunu başarıyor. Goldberg "N sayısını arttırıp 10,20
seviyesine getirsem belki bunları frekans modeli de yapardı ama
hafızam yetmezdi" diye bir yorum da yapmış, ve bu nokta DO / YSA'nın
önemli bir avantajını yakalamış. Frekans modeli mesela 9 harf geriye
bakıp 10. harfi tahmin için, mumkun tum kombinasyonlar icin 20 harflik
alfabede 20**10 öğeli bir sözlük / listeye sahip olmalıdır, bu 10240
milyar öğe demektir. O tüm kombinasyonlar tabii ki girdi verisi içinde
olmayabilir, fakat az bir kısmı olsa bile bu müthiş büyük bir
sayıdır. Halbuki derin öğrenim, her ne kadar modeli derinleştirse de,
her seviye sadece bir sonraki seviyeyle iletişimde olduğu için yer
israf etmiyor. Üstelik bu katmanlı yaklaşımı ile her katmanın belli
alanlara odaklaşmasını teşvik ediyor, böylece model
genelleştirebiliyor. Frekans modeli ezberci, derin öğrenim böyle
değil.</p>

<p>Su yazıyı baz alarak mevcut olan bir DO'yu (LSTM) yükleyip biz de
metin üretme yaptırdık, kurulum için</p>

<div class="codehilite">
<pre><span></span><code><span class="n">sudo</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">tensorflow</span>
<span class="n">sudo</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">h5py</span>
</code></pre>
</div>

<p>Kullanılan DO programı Keras. Kaynak indirilip python setup.py build
ve install ile kurulabilir.</p>

<p>Model</p>

<p>http://www.cs.virginia.edu/~vicente/recognition/notebooks/weights-vicente.hdf5</p>

<p>Alttaki kodu arka arkaya isletince </p>

<p>a black cat is drinking into a bowl on the side of a road
a bike sitting next to a stick is taking his lapkay
a person is standing on a restaurant</p>

<p>gibi cümleler üretiliyor. Kelimelerin çoğunun mantıklı olması bir yana, gramer yapısı da fena değil.</p>

<p>Kod</p>

<div class="codehilite">
<pre><span></span><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">LSTM</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">RMSprop</span>
<span class="kn">from</span> <span class="nn">keras.layers.wrappers</span> <span class="kn">import</span> <span class="n">TimeDistributed</span>

<span class="c1"># Read captions into a python list.</span>
<span class="n">maxSamples</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">captions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">fopen</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;captions_train.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">iterator</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">fopen</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">iterator</span> <span class="o">&lt;</span> <span class="n">maxSamples</span><span class="p">:</span>
        <span class="n">captions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
        <span class="n">iterator</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">fopen</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Compute a char2id and id2char vocabulary.</span>
<span class="n">char2id</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">id2char</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">charIndex</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">caption</span> <span class="ow">in</span> <span class="n">captions</span><span class="p">:</span> 
    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">caption</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">char</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">char2id</span><span class="p">:</span>
            <span class="n">char2id</span><span class="p">[</span><span class="n">char</span><span class="p">]</span> <span class="o">=</span> <span class="n">charIndex</span>
            <span class="n">id2char</span><span class="p">[</span><span class="n">charIndex</span><span class="p">]</span> <span class="o">=</span> <span class="n">char</span>
            <span class="n">charIndex</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># Add a special starting and ending character to the dictionary.</span>
<span class="n">char2id</span><span class="p">[</span><span class="s1">&#39;S&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">charIndex</span><span class="p">;</span> <span class="n">id2char</span><span class="p">[</span><span class="n">charIndex</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;S&#39;</span>  <span class="c1"># Special sentence start character.</span>
<span class="n">char2id</span><span class="p">[</span><span class="s1">&#39;E&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">charIndex</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span> <span class="n">id2char</span><span class="p">[</span><span class="n">charIndex</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;E&#39;</span>  <span class="c1"># Special sentence ending character.</span>

<span class="c1"># Place captions inside tensors.</span>
<span class="n">maxSequenceLength</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">captions</span><span class="p">])</span>
<span class="c1"># inputChars has one-hot encodings for every character, for every caption.</span>
<span class="n">inputChars</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">captions</span><span class="p">),</span> <span class="n">maxSequenceLength</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">char2id</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<span class="c1"># nextChars has one-hot encodings for every character for every caption (shifted by one).</span>
<span class="n">nextChars</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">captions</span><span class="p">),</span> <span class="n">maxSequenceLength</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">char2id</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">captions</span><span class="p">)):</span>
    <span class="n">inputChars</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">char2id</span><span class="p">[</span><span class="s1">&#39;S&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">nextChars</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">char2id</span><span class="p">[</span><span class="n">captions</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">maxSequenceLength</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">captions</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">inputChars</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">char2id</span><span class="p">[</span><span class="n">captions</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]]]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">captions</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
                <span class="n">nextChars</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">char2id</span><span class="p">[</span><span class="n">captions</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]]]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">nextChars</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">char2id</span><span class="p">[</span><span class="s1">&#39;E&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inputChars</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">char2id</span><span class="p">[</span><span class="s1">&#39;E&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">nextChars</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">char2id</span><span class="p">[</span><span class="s1">&#39;E&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;input:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inputChars</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># Print the size of the inputCharacters tensor.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nextChars</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># Print the size of the nextCharacters tensor.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;char2id:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">char2id</span><span class="p">)</span>  <span class="c1"># Print the character to ids mapping.</span>

<span class="n">trainCaption</span> <span class="o">=</span> <span class="n">inputChars</span><span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># Pick some caption</span>
<span class="n">labelCaption</span> <span class="o">=</span> <span class="n">nextChars</span><span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># Pick what we are trying to predict.</span>

<span class="k">def</span> <span class="nf">printCaption</span><span class="p">(</span><span class="n">sampleCaption</span><span class="p">):</span>
    <span class="n">charIds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">sampleCaption</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">elem</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sampleCaption</span><span class="p">):</span>
        <span class="n">charIds</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">elem</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">id2char</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">charIds</span><span class="p">]))</span>

<span class="n">printCaption</span><span class="p">(</span><span class="n">trainCaption</span><span class="p">)</span>
<span class="n">printCaption</span><span class="p">(</span><span class="n">labelCaption</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Building training model...&#39;</span><span class="p">)</span>
<span class="n">hiddenStateSize</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">hiddenLayerSize</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="c1"># The output of the LSTM layer are the hidden states of the LSTM for every time step. </span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">hiddenStateSize</span><span class="p">,</span> <span class="n">return_sequences</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">maxSequenceLength</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">char2id</span><span class="p">))))</span>
<span class="c1"># Two things to notice here:</span>
<span class="c1"># 1. The Dense Layer is equivalent to nn.Linear(hiddenStateSize, hiddenLayerSize) in Torch.</span>
<span class="c1">#    In Keras, we often do not need to specify the input size of the layer because it gets inferred for us.</span>
<span class="c1"># 2. TimeDistributed applies the linear transformation from the Dense layer to every time step</span>
<span class="c1">#    of the output of the sequence produced by the LSTM.</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hiddenLayerSize</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)))</span> 
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">char2id</span><span class="p">))))</span>  <span class="c1"># Add another dense layer with the desired output size.</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">)))</span>
<span class="c1"># We also specify here the optimization we will use, in this case we use RMSprop with learning rate 0.001.</span>
<span class="c1"># RMSprop is commonly used for RNNs instead of regular SGD.</span>
<span class="c1"># See this blog for info on RMSprop (http://sebastianruder.com/optimizing-gradient-descent/index.html#rmsprop)</span>
<span class="c1"># categorical_crossentropy is the same loss used for classification problems using softmax. (nn.ClassNLLCriterion)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">RMSprop</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span> <span class="c1"># Convenient function to see details about the network model.</span>

<span class="c1"># Test a simple prediction on a batch for this model.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample input Batch size:&quot;</span><span class="p">),</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inputChars</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">32</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample input Batch labels (nextChars):&quot;</span><span class="p">),</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nextChars</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">32</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inputChars</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">32</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output Sequence size:&quot;</span><span class="p">),</span>
<span class="nb">print</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">inference_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="c1"># Two differences here.</span>
<span class="c1"># 1. The inference model only takes one sample in the batch, and it always has sequence length 1.</span>
<span class="c1"># 2. The inference model is stateful, meaning it inputs the output hidden state (&quot;its history state&quot;)</span>
<span class="c1">#    to the next batch input.</span>
<span class="n">inference_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">hiddenStateSize</span><span class="p">,</span> <span class="n">batch_input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">char2id</span><span class="p">)),</span> <span class="n">stateful</span> <span class="o">=</span> <span class="kc">True</span><span class="p">))</span>
<span class="c1"># Since the above LSTM does not output sequences, we don&#39;t need TimeDistributed anymore.</span>
<span class="n">inference_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hiddenLayerSize</span><span class="p">))</span>
<span class="n">inference_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">inference_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">char2id</span><span class="p">)))</span>
<span class="n">inference_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">inference_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s2">&quot;weights-vicente.hdf5&quot;</span><span class="p">)</span>

<span class="c1"># Given the start Character &#39;S&#39; (one-hot encoded), predict the next most likely character.</span>
<span class="n">startChar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">char2id</span><span class="p">)))</span>
<span class="n">startChar</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">char2id</span><span class="p">[</span><span class="s1">&#39;S&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">nextCharProbabilities</span> <span class="o">=</span> <span class="n">inference_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">startChar</span><span class="p">)</span>

<span class="c1"># print the most probable character that goes next.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">id2char</span><span class="p">[</span><span class="n">nextCharProbabilities</span><span class="o">.</span><span class="n">argmax</span><span class="p">()])</span>

<span class="n">inference_model</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>  <span class="c1"># This makes sure the initial hidden state is cleared every time.</span>

<span class="n">startChar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">char2id</span><span class="p">)))</span>
<span class="n">startChar</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">char2id</span><span class="p">[</span><span class="s1">&#39;S&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">):</span>
    <span class="n">nextCharProbs</span> <span class="o">=</span> <span class="n">inference_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">startChar</span><span class="p">)</span>

    <span class="c1"># In theory I should be able to input nextCharProbs to np.random.multinomial.</span>
    <span class="n">nextCharProbs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">nextCharProbs</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span> <span class="c1"># Weird type cast issues if not doing this.</span>
    <span class="n">nextCharProbs</span> <span class="o">=</span> <span class="n">nextCharProbs</span> <span class="o">/</span> <span class="n">nextCharProbs</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># Re-normalize for float64 to make exactly 1.0.</span>

    <span class="n">nextCharId</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nextCharProbs</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
    <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">id2char</span><span class="p">[</span><span class="n">nextCharId</span><span class="p">])</span> <span class="c1"># The comma at the end avoids printing a return line character.</span>
    <span class="n">startChar</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">startChar</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">nextCharId</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="nb">print</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</code></pre>
</div>

        </section>          
      </div>
    </body>
</html>
