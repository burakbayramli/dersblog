<!DOCTYPE html>
<html>
  <head>
    <title>Monte Carlo, Entegraller
</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [["$","$"]]}
      });
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    </script>
   <script type="text/javascript"
       src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full">
   </script>
   <script async="async" data-cfasync="false" src="//pl22489825.profitablegatecpm.com/d84f574876e65b2d8f0c7bae784c22b3/invoke.js"></script>

<p><link rel="stylesheet" type="text/css" media="screen" href="https://burakbayramli.github.io/css/style.css">
  </head>
    <body>
      <div id="header_wrap" class="outer">
        <header class="inner">
          <h1 id="project_title">
            <a href="https://burakbayramli.github.io" style="text-decoration:none; color:inherit;">dersblog</a>
          </h1>
          <h2 id="project_tagline"></h2>        <br />
        </header>
      </div>
      <div id="main_content_wrap" class="outer">      <br />
        <section id="main_content" class="inner">
        <h1>Monte Carlo, Entegraller
</h1></p>
<p>Monte Carlo entegrasyonu bir entegral mesela $f(x)$'i sayısal olarak kestirmek
(estimation), ona yakın bir sonuca sayısal olarak erişmenin
yöntemidir. Arkasında yatan teori oldukca basit, diyelim ki $f(x)$'i bir $D$
tanım bölgesi (domain) üzerinden entegre etmek istiyoruz [1].</p>
<p>$$
I = \int_{x \in D} f(x) \mathrm{d} x
$$</p>
<p>Tek değişkenli fonksiyonlar için etki tek boyutlu ve entegrasyon sınırları
basit olarak $a$ ile $b$ arasında.</p>
<p>Biraz cebirsel numara yaparsak, mesela üstteki formülü $p(x)$ ile çarpalım
bölelim (hiçbir değişiklik yaratmamış oluyoruz aslında)</p>
<p>$$
I = \int_{a}^{b} \frac{f(x)}{p(x)} p(x) \mathrm{d} x
$$</p>
<p>$f(x)/p(x)$ bölümüne bir isim verelim, mesela $g(x)$,</p>
<p>$$
I = \int_{a}^{b} g(x) p(x) \mathrm{d} x
$$</p>
<p>Üstteki formül bir beklenti (expectation) hesabına benzemiyor mu? Evet,
$g(x)$'in $p(x)$ yoğunluğu üzerinden beklentisi bu formüldür, </p>
<p>$$
E[g(x)] = I = \int_{a}^{b} g(x) p(x) \mathrm{d} x
$$</p>
<p>Beklenti hesabını örneklem ortalaması ile yaklaşık hesaplayabileceğimizi
biliyoruz, etki alanından $N$ tane $x_i$ örneklemi alalım mesela, o zaman</p>
<p>$$
E[g(x)] \approx
\frac{1}{N} \sum_{i=1}^{N} g(x_i) =
\frac{1}{N} \sum_{i=1}^{N} \frac{f(x_i)}{g(x_i)}
$$</p>
<p>Diyelim ki $a,b$ arasında örneklem aldığımız sayılar birörnek (uniform)
dağılımdan geliyor, yani $p(x)$ birörnek dağılımın yoğunluğu, $p(x) = 1/(b-a)$,
bunu üstteki son formüle sokarsak,</p>
<p>$$
= (b-a) \frac{1}{N} \sum_{i=1}^{N} f(x_i) 
$$</p>
<p>Bu son formül $f(x)$'in $a,b$ arasındaki ortalamasını hesaplıyor ve onu aralığın
uzunluğu ile çarpıyor, bir anlamda bir dikdörtgen alanını hesaplıyoruz,
ki bu dikdörtgenin eni $a,b$ aralığının uzunluğu, yüksekliği ise $f(x)$'in
beklenti değeri.</p>
<p>Mesela $f(x) = x^2$'nin entegralini bulalım, aralık $-2,+2$ arası,</p>
<pre><code class="python">def func1(x):
    return x**2

def func1_int(a, b):
    return (1/3)*(b**3-a**3)

def mc_integrate(func, a, b, n = 1000):
    vals = np.random.uniform(a, b, n)
    y = [func(val) for val in vals]    
    y_mean = np.sum(y)/n
    integ = (b-a) * y_mean    
    return integ

print(f&quot;Monte Carlo çözümü: {mc_integrate(func1, -2, 2, 500000): .4f}&quot;)
print(f&quot;Analitik çözüm: {func1_int(-2, 2): .4f}&quot;)
</code></pre>

<pre><code>Monte Carlo çözümü:  5.3254
Analitik çözüm:  5.3333
</code></pre>

<p>Eğer boyutları arttırsak çözümün genel yapısı değişmiyor mesela üç boyuta çıktık
diyelim [3, sf. 752], entegral hesabı alttaki gibi gözükecekti,</p>
<p>$$
\int_{x_0}^{x_1} \int_{y_0}^{y_1} \int_{z_0}^{z_1}  f(x,y,z) \mathrm{d} x \mathrm{d} y \mathrm{d} z
$$</p>
<p>O zaman Monte Carlo hesabı için $X_i = (x_i,y_i,z_i)$ örneklemi almak gerekir,
çok boyutlu yine birörnek dağılımdan diyelim, ve $p(X)$ hesaplanır, ve kestirme
hesap</p>
<p>$$
\frac{(x_1-x_0)(y_1-y_0)(z_1-z_0)}{N} \sum_i f(X_i)
$$</p>
<p>Bu hesap için bir örnek, iki boyutlu bir fonksiyonun entegralini hesaplayalım,
$f(x) = 10 - x_1^2 - x_2^2$, sınırlar $-2,+2$ olsun.</p>
<pre><code class="python">def func1(x):
    return 10 + np.sum(-1*np.power(x, 2), axis=1)

def mc_integrate(func, a, b, dim, n = 1000):
    x_list = np.random.uniform(a, b, (n, dim))
    y = func(x_list)
    y_mean =  y.sum()/len(y)
    domain = np.power(b-a, dim)
    integ = domain * y_mean
    return integ

print(f&quot;Monte Carlo çözümü : {mc_integrate(func1, -2, 2, 2, 1000000): .3f}&quot;)
print(f&quot;Analitik çözüm: 117.333&quot;)
</code></pre>

<pre><code>Monte Carlo çözümü :  117.305
Analitik çözüm: 117.333
</code></pre>

<p>Doğru Sonuca Yakınsama</p>
<p>Fakat niye Monte Carlo hesaplamanın normal sayısal entegral yöntemlerinden daha
iyi olacağını motive etmedik / açıklamadık. Sonuçta $a,b$ arası birörnek
dağılımdan örneklem almak niye bu aralığı eşit parçalara bölerek dikdörtgen
alanlarını klasik şekilde toplamaktan daha iyi olsun ki?</p>
<p>Bu sorunun cevabı çok boyutlulukta gizli; MC tek boyutta diğer klasik yöntemlere
kıyasla aşağı yukarı aynı cevabı aynı hızda verebilir, fakat yüksek boyutlara
çıktıkça MC yöntemleri parlamaya başlıyor çünkü hataları örneklem büyüklüğü $N$
sayısına bağlı, boyut sayısına değil. Klasik sayısal yöntemlerde boyut arttıkça
hesapsal yükler katlanarak artar, MC bu tür problemlerden korunaklıdır.</p>
<p>İspatlamak için MC tahmin edici / kestirme hesaplayıcı (estimator) varyansını
hesaplamak bilgilendirici olur. Bu varyans bize ortalama hata hakkında ipucu
verecektir, ve hatanın azalmasında hangi faktörlerin rol oynadığını
gösterir. Biraz önce hesaplanan büyüklüğü hatırlarsak, ona $\bar{g}$
diyelim [2, sf. 455],</p>
<p>$$
\bar{g} = \frac{1}{N} \sum_{i=1}^{N} g(X_i)
$$</p>
<p>$$
Var(\bar{g}) = Var \left[ \frac{1}{N} \sum_{i=1}^{N} g(X_i)  \right]
$$</p>
<p>Varyans operasyonu toplamın içine nüfuz edebilir, ayrıca sabitler karesi
alınarak dışarı çıkartılabilir, o zaman</p>
<p>$$
= \frac{1}{N^2} \sum_{i=1}^{N} Var[ g(X_i)]<br />
$$</p>
<p>Eğer herhangi bir $X_1,X_2,..$ değişkenine $X$ dersek ve tüm $X_i$ rasgele
değişkenlerinin varyansı aynı olacağı için üstteki toplam aynı varyansı $N$
kere toplar, o zaman $N$ dışarı çıkartılıp $1/N^2$ deki bir $N$'yi iptal etmek
için kullanılabilir, yani </p>
<p>$$
Var(\bar{g}) = \frac{1}{N} Var[ g(X)]<br />
$$</p>
<p>Her iki tarafın karekökünü alırsak,</p>
<p>$$
\sqrt{Var(\bar{g})} = \frac{1}{\sqrt{N}} \sqrt{Var[ g(X)]}
$$</p>
<p>Yani örneklem ortalamasının standart sapması $\frac{1}{\sqrt{N}}$ oranında
küçülüyor, eğer $n$'yi dört katına çıkartırsak, yani dört kat daha fazla
örneklem kullanırsak, standart sapma yarıya düşüyor. Bu düşüş yüksek boyutlarda
da geçerli oluyor, bu sebeple Monte Carlo yöntemleri klasik sayısal entegral
yöntemlerini yüksek boyutta yenilgiye uğratıyor.</p>
<p>Kaynaklar</p>
<p>[1] Zhao, <em>Monte Carlo integration in Python over univariate and multivariate functions</em>,
    <a href="https://boyangzhao.github.io/posts/monte-carlo-integration">https://boyangzhao.github.io/posts/monte-carlo-integration</a></p>
<p>[2] Gezerlis, <em>Numerical Methods in Physics with Python</em></p>
<p>[3] Pharr, <em>Physically Based Rendering 3rd Ed</em></p>
          <div id="container-d84f574876e65b2d8f0c7bae784c22b3"></div>

          <br/><a href="../index.html">Yukarı</a>
        </section>          
      </div>
    </body>
</html>
