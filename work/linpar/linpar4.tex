\documentclass{article}
\usepackage{PRIMEarxiv}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{palatino,eulervm}
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{fancyhdr}       % header
\usepackage{graphicx}       % graphics
\graphicspath{{media/}}     % organize your images and other figures under media/ folder

\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }} 

\fancyhead[LO]{SVD Factorization for Tall-and-Fat Matrices on Parallel Architectures}
  
\title{SVD Factorization for Tall-and-Fat Matrices on Paralel Architectures}

\author{
  Burak Bayramlı \\
  İstanbul, Turkey\\
  \texttt{burakbayramli.github.io} 
}

\begin{document}

\maketitle

\begin{abstract}
We demonstrate an implementation for an approximate rank-k SVD factorization,
combining well-known randomized projection techniques with previously known
paralel solutions in order to compute steps of the random projection based SVD
procedure. We structure the problem in a way that it reduces to fast computation
around $k \times k$ matrices computed on a single machine, greatly easing the
computability of the problem. The paper is also a tutorial on paralel linear
algebra methods using a plain architecture without burdensome frameworks.
\end{abstract}


% keywords can be removed
\keywords{Parallel \and Concurrency \and Big Data}

\section{Introduction}

Parallelization for Big Data type problems where we are presented with many
rows, reaching upwards of billions, large (but not as many) columns, can be
achieved by processing the input file line by line where the process
contributes, furthers the computation at each line, accumulating a small result
in memory, or written out to disk as a line, at each iteration. Parallel
implementation can be possible by assuming each process on each machine has
access to a large file, can process different parts of this big file, either
through copies of that file being in each machine, or through a shared file
server on a fast Ethernet network. As most number crunching applications are CPU
bound, potential IO blockages are deemed as less of an issue for such problems.

Many methods in Linear Algebra can be reframed this way where line-by-line
computation is pursued, the processing starts with first line, computes, and
goes further down, furthering the computation each step after which results from
each process are added up.

\section{Linear Algebra Basics}

\subsubsection{Singular Value Decomposition}

Computing SVD on an $m \times n$ matrix where $m$ is large can be
taxing. However by making use of $A$'s representation as $A = U \Sigma V^T$, and
computing $A^TA$, we realize \cite{zadeh},

$$
A^TA = V \Sigma^2 V^T 
$$

The righthand side has reduced to an eigenvector calculation. Therefore by
computing $A^TA$ we are computing $V \Sigma^2 V^T $ on which we can run
eigenvector calculation to obtain the $V$ vector. The approach can be more more
optimal because if $A$ is $m \times n$ where $n << m$, therefore $A^TA$
dimensions has to be $n \times n$ a much smaller matrix that can fit in memory.
Therefore the SVD calculation of a large $A$ is reduced eigenvector calculation
of a smaller $A^TA$.

Calculating $U$ can be done as follows,

$$
A = U \Sigma V^T \to U = A V \Sigma^{-1}
$$

\subsubsection{Incremental $A^T A$}

We have reduced incremental, parallel computation of SVD to parallel computation
of $A^T A$. That problem can be solved by noticing $A^T A$ is easily computed
through the outer product of $i$'th row of the matrix, $A_{i}$ with itself, and
summing the results.

$$
A^T A = \sum_{i} A_i \times A_i
$$

Summation is commutative, therefore outer products from each machine / node, per
row can be added together, no matter the order, first at each node as a
local sum, than as a global sum once the processing of each node is finished.

Simple Python code demonstration,

\begin{verbatim}
A = [[1,2,3],
     [3,4,5],
     [4,5,6],
     [6,7,8]]
A = np.array(A)

s = np.zeros((3,3))
for i in range(4):
  s = s + np.outer(A[i,:],A[i,:])
print (s)    
\end{verbatim}

\begin{verbatim}
[[ 62.  76.  90.]
 [ 76.  94. 112.]
 [ 90. 112. 134.]]
\end{verbatim}

\subsubsection{Multiplication}

Now we need to handle the case of large $n$. We propose reducing the size of $A$
through random projection obtaining an approximation. This approximation works
for the reason that projecting points to a random subspace preserves distances
between points, or in detail, projecting the n-point subset onto a random
subspace of $O(\log n/\epsilon^2)$ dimensions only changes the interpoint
distances by $(1 \pm \epsilon)$ with positive probability \cite{gupta}. It is
also said that projected matrix $Y$ is a good representation of the span of $A$.

Now we need a way to incrementally multiply matrix $A$ with another matrix $B$
which is a random matrix with size $n \times k$ where $k$ is much smaller and
manageable than $n$. The multiplication will give us $m \times k$, therefore
$A^TA$ will result in $k \times k$, on which SVD through eigenvectors can be
calculated easily.

Incremental multiplication in pseudocode is as follows,

\begin{verbatim}
for(int m = 0; m < M; m++) {
    for(int k = 0; k < K; k++) {
        for(int n = 0; n < N; n++) {
            C[m][n] += A[m][k]*B[k][n];
        }
    }
}
\end{verbatim}

\begin{figure}[h]
  \centering
  \includegraphics[width=20em]{mult1.jpg}
  \caption{Two Steps of a Row Based Multiplication Process}
  \label{fig:mult1}
\end{figure}

Simple Python code can demonstrate multiplication of one row of $A$,
with all of $B$,

\begin{verbatim}
a = np.array([[1,2,3]]).T
B = np.array([[3,4,5],[1,1,1],[2,2,2]])
print (a); print (B)
print (a*B)
\end{verbatim}

\begin{verbatim}
[[1]
 [2]
 [3]]
[[3 4 5]
 [1 1 1]
 [2 2 2]]
[[3 4 5]
 [2 2 2]
 [6 6 6]]
\end{verbatim}

In this paper we assumed matrix $B$, in dimensions $n \times k$, can be brought
into memory completely. The operation as seen above will be computed for each
row of $A$ and the results will be summed.

\section{Implementation}

Big Data became possible largely thanks to Map-Reduce architectures which
represent splitting (mapping) and grouping (reducing) concepts logically and
present them the only interface for a programmer to worry about, while in the
background directing data pieces produced by mapping and reducing to appropiate
seperate nodes to achieve concurrency. A sample process is seen in
Figure~\ref{fig:mapreduce1},

\begin{figure}[h]
  \centering
  \includegraphics[width=20em]{mapreduce1.jpg}
  \caption{Example of Map-Reduce}
  \label{fig:mapreduce1}
\end{figure}

Our proposal is a simpler, so-called Split-Process architecture. Each process
has access to a large file, is able to skip ahead to any row of that file,
distribution is done on the basis of processing a pre-decided subset of all
data. 

\begin{figure}[h]
  \centering
  \includegraphics[width=15em]{splitprocess.jpg}
  \caption{Split-Process}
  \label{fig:mapreduce1}
\end{figure}

The nature of the computation described previously fits perfectly with this
approach. With four processes and 1000 lines to process, each process
$i=1,2,3,4$ can be directed to focus on their portion of the file, first can
take rows $1,..,250$, the next can take $251,..,500$, so on.

Here we present the main processor of the code, called \verb!split_process!
which can determine line beginning and end points in terms of seek byte
locations of a given file, and by inspecting the \verb!workobj.ci! will
jump ahead toward the chunk and start reading the file line by line, and
feed them into \verb!workobj.exec!. In an object-oriented design each
\verb!workobj! will know how to handle an input line, will either accumulate
results from it or write an output itself to another file.

\begin{verbatim}
import os, numpy as np

def split_process(file_name,N,workobj):
    file_size = os.path.getsize(file_name)
    beg = 0
    chunks = []
    for i in range(N):
        with open(file_name, 'r') as f:
            s = int((file_size / N)*(i+1))
            f.seek(s)
            f.readline()
            end_chunk = f.tell()-1
            chunks.append([beg,end_chunk])
            f.close()
        beg = end_chunk+1
    c = chunks[workobj.ci]
    with open(file_name, 'r') as f:
        f.seek(c[0])
        while True:
            line = f.readline()
            workobj.exec(line)
            if f.tell() > c[1]: break
        f.close()
        workobj.post()
\end{verbatim}

The results, if they can be accumulated in memory, can be kept on
\verb!workobj!. Once a chunk is finished (all its rows are visited) then
\verb!split_process! will call \verb!workobj.post! which can handle disk output,
cleaning up operations.

The job classes for $A^T A$, $AB$ are given below.

\subsection{Calculation of $A^T A$}

\begin{verbatim}
class ATAJob:
    def __init__(self,D,ci):
        self.C = np.zeros((D,D))
        self.ci = ci
    def exec(self,line):
        tok = line.split(';')
        vec = np.array([float(x) for x in tok])
        self.C = self.C + np.outer(vec, vec)
    def post(self):
        outfile = "/tmp/C-%d.csv" % self.ci
        np.savetxt(outfile, self.C, delimiter=';',fmt='%1.6f')
\end{verbatim}

\subsection{Multiplication of $A$ and $B$}

\begin{verbatim}
class MultJob:
    def __init__(self,ci,bfile):
        self.afile = ""
        self.B = np.loadtxt(bfile,delimiter=';')
        self.ci = ci
        cname = "%s/C-%d.csv" % (os.path.dirname(afile), self.ci)
        self.outfile = open(cname, "w")        
    def exec(self,line):        
        vec = np.array([np.float(x) for x in line.strip().split(";")])
        vec = np.reshape(vec, (len(vec),1))
        res = (vec * self.B).sum(axis=0).tolist()  
        res = ";".join(map(str, res))
        self.outfile.write(res)
        self.outfile.write("\n")
        self.outfile.flush()
    def post(self):
        self.outfile.close()
\end{verbatim}


%Bibliography
\bibliographystyle{unsrt}  

\begin{thebibliography}{1}

\bibitem{gleich}
Gleich, Benson, Demmel, \emph{Direct QR factorizations for tall-and-skinny
  matrices in MapReduce architectures}, {\tt arXiv:1301.1071 [cs.DC]}, 2013

\bibitem{halko}
N.~Halko, \emph{Randomized methods for computing low-rank approximations of
  matrices}, University of Colorado, Boulder, 2010

\bibitem{gupta}
S.~Dangupta, A.~Gupta \emph{An Elementary Proof of a Theorem of Johnson and
  Lindenstrauss}, Wiley Periodicals, 2002

\bibitem{kurucz}
M.~Kurucz, A. A.~Benczúr, K.~Csalogány, \emph{Methods for large scale SVD with
missing values}, ACM, 2007

\bibitem{zadeh}
Zadeh, \emph{CME 323: Distributed Algorithms and Optimization, Lecture 17}, 
\url{https://stanford.edu/~rezab/classes/cme323/S17/}

\bibitem{agrawal}
Agrawal, \emph{Matrix Multiplication: Inner Product, Outer Product and Systolic Array},
\url{https://www.adityaagrawal.net/blog/architecture/matrix_multiplication}
  
\end{thebibliography}

\end{document}
