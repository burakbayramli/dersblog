<!DOCTYPE html>
<html>
  <head>
    <title>Uzaklıklar, Norm, Benzerlik
</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [["$","$"]]}
      });
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    </script>
   <script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full">
   </script>
   <link rel="stylesheet" type="text/css" media="screen" href="https://burakbayramli.github.io/css/style.css">
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1548953794786292"
          crossorigin="anonymous"></script>  
  </head>
    <body>
      <div id="header_wrap" class="outer">
        <header class="inner">
          <h1 id="project_title">
            <a href="https://burakbayramli.github.io" style="text-decoration:none; color:inherit;">dersblog</a>
          </h1>
          <h2 id="project_tagline"></h2>          
        </header>
      </div>
      <div id="main_content_wrap" class="outer">        
        <section id="main_content" class="inner">
        <h1>Uzaklıklar, Norm, Benzerlik
</h1>

<p>Literatürdeki anlatım norm ve uzaklık konusu etrafında biraz kafa karışıklığı
yaratabiliyor, bu yazıda biraz açıklık getirmeye çalışalım. Norm bir büyüklük
ölçüsüdür. Vektör uzayları ile olan alakasını görmek için {\em Fonksiyonel
  Analiz} notlarına bakılabilir. Büyüklük derken bir $x$ vektörünün
büyüklüğünden bahsediyoruz, ki bu çoğunlukla $||x||$ gibi bir kullanımda
görülür, eğer altsimge yok ise, o zaman 2 kabul edilir, yani $||x||_2$. Bu ifade
bir L2 norm'unu ifade eder. $||x||_1$ varsa L1 norm'ü olurdu.</p>
<p>L1,L2 normaları, ya da genel olarak $p$ üzerinden $L_p$ normları şöyle gösterilir,</p>
<p>$$ ||x||_p = (\sum_i |x_i|^p)^{1/p} $$</p>
<p>ki $x_i$, $x$ vektörü içindeki öğelerdir. Eğer $p=2$ ise, L2 norm</p>
<p>$$ ||x||_2 = \bigg(\sum_i |x_i|^2 \bigg)^{1/2} $$</p>
<p>Üstel olarak $1/2$'nin karekök demek olduğunu hatırlayalım, yani </p>
<p>$$ ||x||_2 = \sqrt{\sum |x_i|^2} $$</p>
<p>Bu norm ayrıca Öklitsel (Euclidian) norm olarak ta bilinir, tabii ki bunun
Öklitsel uzaklık ile yakın bağlantısı var (iki vektörü birbirinden çıkartıp
Öklit normunu alırsak Öklit uzaklığını hesaplamış oluruz).</p>
<p>Eğer $p=1$ olsaydı, yani L1 norm, o zaman üstel olarak $1/1$ olur, yani hiçbir
üstel / köksel işlem yapılmasına gerek yoktur, iptal olurlar,</p>
<p>$$ ||x||_1 = \sum |x_i|^2 $$</p>
<p>Örnek</p>
<p>$$ 
a = \left[\begin{array}{r}
3 \\ -2 \\ 1
\end{array}\right]
 $$</p>
<p>$$ ||a|| = \sqrt{3^2+(-2)^2+1^2} = 3.742 $$</p>
<p>Örnekte altsimge yok, demek ki L2 norm. </p>
<p>Ek Notasyon, İşlemler</p>
<p>L1 normu için yapılan işlemi düşünelim, vektör öğeleri kendileri ile
çarpılıyor ve sonuçlar toplanıyor. Bu işlem</p>
<p>$||x||_1 = x^Tx$</p>
<p>olarak ta gösterilemez mi? Ya da $x \cdot x$ olarak ki bu noktasal çarpımdır.</p>
<p>Bazen de yapay öğrenim literatüründe $||x||^2$ şekilde bir kullanım
görebiliyorsunuz. Burada neler oluyor? Altsimge yok, demek ki L2
norm. Sonra L2 normun karesi alınmış, fakat L2 normu tanımına göre bir
karekök almıyor muydu? Evet, fakat o zaman kare işlemi karekökü iptal eder,
demek ki L2 normunun karesini almak bizi L1 normuna döndürür! Eh bu normu
da $x^Tx$ olarak hesaplayabildiğimize göre hemen o notasyona geçebiliriz,
demek ki $||x||^2 = x^Tx = x \cdot x$. </p>
<p>İkisel Vektörlerde Benzerlik</p>
<p>Diğer ilginç bir kullanım ikisel değerler içeren iki vektör arasında
çakışan 1 değerlerinin toplamını bulmak. Mesela </p>
<pre><code class="python">a = np.array([1,0,0,1,0,0,1,1])
b = np.array([0,0,1,1,0,1,1,0])
</code></pre>

<p>Bu iki vektör arasındaki 1 uyusumunu bulmak için noktasal çarpım yeterli,
çünkü 1 ve 0, 0 ve 1, 0 ve 0 çarpımı sıfır verir, ama 1 çarpı 1 = 1
sonucunu verir. O zaman L1 norm bize ikisel iki vektör arasında kabaca bir
benzerlik fikri verebilir.</p>
<pre><code class="python">print np.dot(a,b)
</code></pre>

<pre><code>2
</code></pre>

<p>Matris Normları</p>
<p>Vektörlerin norm'ü hesaplanabildiği gibi matris norm'ü da hesaplanabilir. Bir
$A$ matrisi için matris norm'ü</p>
<p>$$ || A || = \sup { ||Ax|| : x \in \mathbb{R}^n, ||x||=1 \textrm{ olacak şekilde } } $$</p>
<p>Bazen şöyle de gösterilir,</p>
<p>$$  || A || = \sup_{||x||=1} { ||Ax|| } $$</p>
<p>ya da</p>
<p>$$ || A || = \sup { \frac{||Ax||}{||x||} : x \in \mathbb{R}^n, x \ne 0 \textrm{ olacak şekilde } } $$</p>
<p>Daha genel formda p-norm'u</p>
<p>$$ || A || = \sup
\bigg\{
\frac{||Ax||_p}{||x||_p} : x \in \mathbb{R}^n, x \ne 0 \textrm{ olacak şekilde }
\bigg\} $$</p>
<p>Özel durum $p=2$ için ki bu yine, vektörler için olduğu gibi, Öklitsel norm
olarak biliniyor. Bu durumda $A$'nın normu $A$'nın en büyük eşsiz
değeridir. Yaklaşık olarak hesaplama açısından şunu da verelim,</p>
<p>$$ ||A||<em>1 = \max</em>{1 \le j \le n} \sum_{i=1}^{m} |a_{ij}| $$</p>
<p>Yani tüm matris kolonlarının hücrelerinin mutlak değerleri toplanıyor, bu
toplamlar arasında en büyük sayıyı veren kolonun toplamı normun yaklaşık
değeridir.</p>
<p>Spektral (Operatör) ve İz (Trace) Norm</p>
<p>Bu normlar sırasıyla matrisin en büyük eşsiz (singular) değeri, ve tüm
eşsiz değerlerinin toplamıyla hesaplanır. Bir matris $X$ için operatör norm</p>
<p>$$
||X||_{op} = \sigma_1(X)
$$</p>
<p>İz normu</p>
<p>$$
||X||<em>{tr} = \sigma</em>{i=1}^{r} \sigma_i(X)
$$</p>
<hr>

<p>$$ (x-v)^TA(x-v) &lt; 1 $$</p>
<p>Üstteki formülde $x$ yerine $Px$ geçirirsek, ki $P$ herhangi bir matris,
eşitsizliğin sol tarafına ne olur?</p>
<p>$$ (P(x-v))^T A (P(x-v))$$</p>
<p>$$ (x-v)^T P^T A P (x-v)  $$</p>
<p>Bu formüle bir şekilde ulaşmamız lazım. Ama nasıl? Basitleştirme amaçlı olarak
$w = x-v$ tanımlayalım, ki $x \ne v$ olacak şekilde. $X = \frac{1}{||w||^2} I$
tanımlayalım, bu bir köşegen matris, köşegeninde $1/||w||^2$ değerleri var. Bu
sayede</p>
<p>$$ w^T A W &lt; 1  \Rightarrow w^T A W &lt; w^T X w  $$</p>
<p>1 yerine üstteki en sağdaki terimi kullanmış olduk. Herhangi bir $x$ için
üstteki eşitsizlik her $w$ için doğru olacaktır. Bu da $A - X$ negatif kesin
demektir (pozitif kesinliğin tersi), o zaman şunu da söyleyebiliriz,</p>
<p>$$ A - X &lt; 0 \Rightarrow P^T(A-x)P &lt; 0 \Rightarrow P^T AP &lt; P^TXP $$</p>
<p>Soldan ve sağdan $w^T,w$ ile çarparsak,</p>
<p>$$ w^T P^T AP w &lt; w^T P^TXP w = \frac{1}{||w||^2} w^T P^T P w = (Pu)^T Pu$$</p>
<p>ki $u = \frac{w}{||w||}$ $x-v$ yönünü gösteren birim vektördür. </p>
<p>Şimdi matris normunun ne olduğunu hatırlayalım,</p>
<p>$$ ||P|| = \sup_{||u||=1} || Pu || $$</p>
<p>O zaman emin bir şekilde diyebiliriz ki </p>
<p>$$ (x-v)^TA(x-v) &lt; 1 \Rightarrow (x-v)^T P^T A P (x-v) &lt; ||P||^2 $$</p>
<hr>

<p>Sherley-Morrison Formülü</p>
<p>Bu formülün temeli şu eşitlikten başlıyor [1, sf. 124],</p>
<p>$$
(I+cd^T)^{-1} = I - \frac{cd^T}{1+d^Tc}
\qquad (1)
$$</p>
<p>ki $c,d$ birer vektör, ve $1+d^Tc \ne 0$ olacak şekilde, üstteki eşitliğin
doğru olduğunu kontrol için iki tarafı $(I+cd^T)$ ile çarpabiliriz, eğer
sağ tarafta birim matrisi elde edersek eşitlik doğru demektir,</p>
<p>$$
I + cd^T - \frac{cd^T (I + cd^T)}{1+d^Tc}
$$</p>
<p>$$
= I + cd^T - \frac{I cd^T (1+cd^T)}{1+d^Tc}
$$</p>
<p>$$
= I + cd^T - cd^T = I
$$</p>
<p>Eğer sıfırdan başlayarak türetmek istesek, öyle bir $\alpha$ arıyoruz ki
$(I + cd^T)$ ifadesini $(I + \alpha cd^T)$ ile çarpınca bize birim matrisi
versin. Çarpımı yaparsak,</p>
<p>$$
(I + cd^T) (I + \alpha cd^T) = I + cd^T + \alpha cd^T + \alpha cd^Tcd^T 
$$</p>
<p>$$
= I + (1 + \alpha + \alpha d^T c) cd^T
$$</p>
<p>Üsttekinin birim matrisi $I$ olması için $1 + \alpha + \alpha d^T c$ sıfır
olmalı, onun sıfır olması için de</p>
<p>$$\alpha = \frac{-1}{1 + d^Tc}$$</p>
<p>doğru olmalı. $\alpha$'yi yerine koyarsak, </p>
<p>$$
(I + \alpha cd^T) = I - \frac{cd^T}{1+d^Tc}
$$</p>
<p>elde ederiz, yani $(I + \alpha cd^T)^{-1}$ açılımı budur. </p>
<p>Sherman-Morrison formülü </p>
<p>$$
(A + cd^T)^{-1} = A^{-1} - \frac{A^{-1} cd^T A^{-1} }{1 + d^TA^{-1}c}
$$</p>
<p>Bu formüle erişmek için $(A + cd^T)^{-1}$ ile başlayalım, $A$'yi parantez
dışına çekersek,</p>
<p>$$
(A + cd^T)^{-1} = \big( A ( I + A ^{-1} cd^T ) \big)^{-1} 
$$</p>
<p>$$
= ( I + A ^{-1} cd^T )^{-1} A^{-1} 
$$</p>
<p>Parantez içinin (1)'in sol tarafına benzediğini görebiliriz, $b = A^{-1}c$ 
desek,  $( I + bd^T )^{-1} $ açılımıni yapıyor olurduk, </p>
<p>$$
( I + bd^T )^{-1} 
= I - \frac{bd^T}{1+d^Tb} 
= I - \frac{A^{-1}cd^T}{1+d^TA^{-1}c}
$$</p>
<p>Bu sonucu iki üstteki parantez içindeki $A ( I + A ^{-1} cd^T$ yerine
koyarsak,</p>
<p>$$
(A + cd^T)^{-1} = I - \frac{A^{-1}cd^T}{1+d^TA^{-1}c} A^{-1} 
$$</p>
<p>sonucuna erişmiş oluyoruz. </p>
<p>Sherman-Morrison-Woodburry</p>
<p>Bu son formül Sherman-Morrison formülünün daha genelleştirilmiş hali
[3]. Diyelim ki $A \in \mathbb{R}^{n \times n}$ eşsiz değil, ve
$U,V \in \mathbb{R}^{n \times p}$ öyle ki </p>
<p>$$
U + V^T A^{-1} U \in \mathbb{R}^{p \times p}
$$</p>
<p>O zaman </p>
<p>$$B = A + UV^T$$</p>
<p>eşsiz değildir, ve </p>
<p>$$
B^{-1} = A^{-1} - A^{-1} U ( I + V^T A^{-1} U)^{-1} V^T A^{-1} 
$$</p>
<hr>

<p>Gereğinden Fazla Calculus</p>
<p>(MİT üniversitesi Matematik hocası Gilbert Strang'in MİT üniversitesine hitaben
bir yazısından [9] alınmıştır)</p>
<p>Calculus I, Calculus II, Calculus III - öğretim sistemimizde ne kadar büyük bir
dengesizlik! Matematiğin geri kalan kısmı Calculus tarafından boğuldu
denebilir. Bu kadar Calculus dersinden sonra takip eden ders herhalde Türevsel
Denklemler (gene Calculus), Calculus'tan önceki ders'te herhalde Calculus'a
Giriş dersi idi. Arkadaşlar, bu dengesizliği düzeltmek bizim görevimiz, bunu
başkasından bekleyemeyiz. Lineer cebir'in ne kadar önemli bir ders olduğunu
biliyoruz. Bu ders seçmeli/rasgele alınan bir ders değil, uygulama olarak birçok
öğrenciye Calculus'dan daha faydalı olacak bir ders. Artık sayısal bir dünyada
yaşıyoruz. Bu konu hakkında dünyadaki hocalara öncü ve örnek olmamızı istediğim
için, Lineer Cebir'in faydalarından bahsetmek istiyorum. Özetle şöyle
düşünüyorum: Eğer şu ankinden daha fazla öğrenci Lineer Cebir öğreniyor ise,
matematik bölümü bir şeyleri doğru yapıyor demektir. İstatistik ve Ayrıksal
Matematik te lazım. Umarım bölüm başkanı ve rektör onaylar. İnanıyorum ki bu
sayede öğrencilerimi için doğru şeyi yapmış olacağız.İzin verirseniz, lineer
cebir ders basamaklarından bahsedeyim. Mesela dersin her aşaması belli
denklemlerin çözümüne, ya da o denklemleri çözmeye temel olan fikirlere ve
algoritmalara göre ayırılabilir. Bu safhalar birbirini tamamlamalıdır. Mesela 4
denklemi merkez olarak alabiliriz.</p>
<p>$$
Ax = b, \quad A'Ax = A'b, \quad Ax = \lambda x, \quad \mathrm{d} u / \mathrm{d} t = Au
$$</p>
<p>En önemli nokta, herhangi bir uygulama için (gerçek dünyada) bir doğrusal
'sistemi' görebilmek. Şu bizim ünlü A matrisimizi bulabilmek, tanımlayabilmek ne
kadar önemli değil mi? Bunun sonrasında tabii ki o matris üzerinde işlem
yapmamıza yardımcı olacak fikirler takip edecek.</p>
<ul>
<li>
<p>Alt-uzaylar ve bazlar, izdüşümler ve dikgenlik, özvektörler ve özdeğerler</p>
</li>
<li>
<p>Algoritmalar da çok önemli (matris çarpımı da buna dahil)</p>
</li>
<li>
<p>Ax = kolonların katışımı, A = LU ile yokedilmesi, sonra Gram-Schmidt işlemi</p>
</li>
</ul>
<p>En mühim konu da 'doğrusal dönüşüm'. Eğer bir problem içinde matrisin bazına ne
olduğunu biliyorsak, her şeyi biliyoruz demektir. Ben örneklere odaklanabilirim,
siz ispatlara odaklanabilirsiniz, ama sınıfın ne beklediğine her zaman
kulağımızı açık tutalım.Tekrar ana konuya döneyim, çünkü hepimizin yardımını ve
eylemini gerektiriyor. Lineer cebir hakkında çoğunlukla destek görüyoruz, ya da
aldırmazlık görüyoruz. Öteki hocaların da kendi yapacak işleri var, hattâ ve
hattâ üst düzey mühendisler bile lineer cebiri istenmeyen bir şey olarak
görebiliyorlar. Belki de bilgisayarların işleri nasıl değiştirdiğinin farkında
değiller. Fakat sonuçta öğrencileri önde tutarak doğru seçimi
yapacaklardır. Öğrenciler durumu anladığında hocalarımız da doğru seçimi
yaptıklarını inanacaklarına eminim. Calculus I, II ve III derslerinin kendisinin
reform edilmesi bu sunumun dışında. Bu dersler de önemli, ama hayat-memat
seviyesinde değil. Öğrencilerin çoğuna 'yararlı' olacak türden matematik
öğretmek bizim görevimiz.</p>
<p>Kaynaklar </p>
<p>[1] Meyer, <em>Matrix Analysis and Applied Linear Algebra</em></p>
<p>[2] Gadzinski, {How to Derive the Sherman-Morrison Base Formula, Math Stackexchange Sorusuna Cevap}, 
    <a href="https://math.stackexchange.com/a/3462542/6786">https://math.stackexchange.com/a/3462542/6786</a></p>
<p>[3] Gockenbach, <em>Numerical Optimization MA 5630, Globalizing Newton's method: Descent Directions (II)</em>
    <a href="https://pages.mtu.edu/~msgocken/ma5630spring2003/lectures.html">https://pages.mtu.edu/~msgocken/ma5630spring2003/lectures.html</a></p>
<p>[4] Marmer, <em>Economics 627 Econometric Theory II, Vector and Matrix Differentiation</em>, 
    <a href="http://faculty.arts.ubc.ca/vmarmer/econ627/">http://faculty.arts.ubc.ca/vmarmer/econ627/</a></p>
<p>[5] Duda, Hart, <em>Pattern Classification</em></p>
<p>[6] Bishop, <em>Pattern Recognition and Machine Learning</em></p>
<p>[7] Wikipedia, <em>Matrix norm</em>, 
    <a href="https://en.wikipedia.org/wiki/Matrix_norm">https://en.wikipedia.org/wiki/Matrix_norm</a></p>
<p>[8] Thibshirani, <em>Convex Optimization</em>, 
    <a href="https://www.stat.cmu.edu/~ryantibs/convexopt">https://www.stat.cmu.edu/~ryantibs/convexopt</a></p>
<p>[9] Strang, <em>Too Much Calculus</em>,
    <a href="http://web.mit.edu/18.06/www/Essays/too-much-calculus.pdf">http://web.mit.edu/18.06/www/Essays/too-much-calculus.pdf</a></p>
<hr>

<p>Yunan Harfleri</p>
<p><img alt="" src="../../algs/algs_999_zapp/letters.png" /></p>
          <br/><a href="../index.html">Yukarı</a>
        </section>          
      </div>
    </body>
</html>
