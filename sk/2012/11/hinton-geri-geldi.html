
<!DOCTYPE html>
<html>
  <head>
    <title></title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [["$","$"]]}
      });
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    </script>
   <script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full">
   </script>
   <link rel="stylesheet" type="text/css" media="screen" href="https://burakbayramli.github.io/css/style.css">
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1548953794786292"
          crossorigin="anonymous"></script>  
  </head>
    <body>
      <div id="header_wrap" class="outer">
        <header class="inner">
          <h1 id="project_title">
            <a href="https://burakbayramli.github.io" style="text-decoration:none; color:inherit;">dersblog</a>
          </h1>
          <h2 id="project_tagline"></h2>          
        </header>
      </div>
      <div id="main_content_wrap" class="outer">        
        <section id="main_content" class="inner">
        <h1></h1>
<h1>Hinton Geri Geldi</h1>

<p>Yapay Sinir Aglari alaninda unlu Geoffrey Hinton, Derin Ogrenme (Deep
Learning -DL-) adli bir teknikle geri geldi. YSA (ve Hinton), 90'li
yillarda SVM ve benzer tekniklerin parlamasi ile biraz arka planda
kalmisti. Ama o sirada, ve son yenilik oncesi, Hinton Kisitli Boltzman
Makinalari (Restricted Boltzman Machines -RBM) alaninda ilerlemeler
yapmis; ve en son DL tekniginde ust uste konulan RBM'ler arasinda bir
hiyerarsi olusturarak ses ve goruntu tanimada ciddi ilerlemeler
kaydetmeyi basardi. Bu bulus etrafinda bayagi gurultu kopuyor bu
gunlerde, acaba evrensel ogrenme algoritmasi  bu mu? gibi
dusunceler.. DL, tamamen paralel sekilde kullanilmaya acik, Hinton'a
gore ne kadar fazla donanim, ne kadar fazla paralellik eklenirse DL o
kadar daha iyi isleyecektir.</p>

<p>Hinton ve arkadaslari gecende girdikleri bir Kaggle yarismasinda az
bir veri uzerinde (ki eski YSA'lar genelde cok veriye ihtiyac
duyarlardi), fazla "veri hazirlama"dan son anda girip birinciligi
kazandilar. Bir diger makalede, yine ayni grup, daha onceki bir
yarisma Netflix verisi uzerinde toplam filtrelemede (collaborative
filtering) o yarismayi kazanmis olan ve dikkatle ayarlanmis SVD bazli
algoritmayi hic ayarlanmamis RBM ile az da olsa gectiklerini
yazdilar..</p>

<p>Diger yonde bir gorus surada.</p>

<p>Derin  Ogrenim'i Hinton burada anlatiyor</p>

          <br/><a href="../index.html">YukarÄ±</a>
        </section>          
      </div>
    </body>
</html>
