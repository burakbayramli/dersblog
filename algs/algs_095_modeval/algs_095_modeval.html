<h1>Model Başarısını Ölçmek</h1>
<!DOCTYPE html>
<html>
  <head>
    <title>Model Başarısını Ölçmek
</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [["$","$"]]}
      });
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    </script>
<script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full">
</script>
</head>

<p>Eğitim ve kontrol (validation) verisini ayrı tutmak iyi fikirdir, model
eğitim verisinde eğitilir, kontrol verisinde kontrol edilir. Yani modelin
hiç görmediği veriler üzerinde kontrolünün yapılması gerekir. Bazen bu
ayrışmanın veri üzerinde olan bir değer üzerinden olması da istenebilir,
mesela parakende satış verileri üzerinde eğitim yapıyorsak, bir müşterinin
hem eğitim hem kontrol verisinde olmasını istemeyebiliriz. Bu durumda
ayırma nasıl yapılır? Çok basit bir yöntem kullanıcı kimliği üzerinde
<code>hash</code> çağrısı yapmak ve sonuç üzerinde 2 üzerinden (mesela) modülo
uygulamak. Eğer çift sayı ise eğitim tek ise kontrol. Böylece ayrı bir
liste tutmadan kimliğe bakarak direk ayrımı yapabilmiş oluruz.  </p>
<p>Kafa Karışıklığı Matrisi (Confusion Matrix) </p>
<p>İki ya da daha fazla etiketli tahmin problemlerinin sonuçlarını irdelemek
için kafa karışıklığı matrisi (KKM) kullanılabilir. Bu matrisin dikey
eksenini test verisinde gerçekten olan etiket, yatay eksenini tahmin edilen
etiket olarak düşünürsek, kordinate kesişimleri her özgün etiket değeri
için tahmin etme başarısını gösterecektir. Mesela herhangi bir yapay
öğrenim algoritmasından <code>y_tahmin</code> üretilmiş olsun,</p>
<pre><code class="python">from sklearn.metrics import confusion_matrix
y_gercek = [&quot;kedi&quot;, &quot;sinek&quot;, &quot;kedi&quot;, &quot;kedi&quot;, &quot;sinek&quot;, &quot;balik&quot;]
y_tahmin = [&quot;sinek&quot;, &quot;sinek&quot;, &quot;kedi&quot;, &quot;kedi&quot;, &quot;sinek&quot;, &quot;kedi&quot;]
print confusion_matrix(y_gercek, y_tahmin, labels=[&quot;sinek&quot;, &quot;balik&quot;, &quot;kedi&quot;])
</code></pre>

<pre><code>[[2 0 0]
 [0 0 1]
 [1 0 2]]
</code></pre>

<p>Bakıyoruz gerçekten sinek olduğu zaman 2 kere sinek tahmin edilmiş
(matriste sol üst köşe), kedi aynı şekilde iki, ama bir defa kedi için
sinek denmiş, bu matrisin sol alt köşesinde. KKM matrisi tüm bu doğruları,
hataları tek bir yerde gösterebilen faydalı bir raporlama aracıdır. </p>
<p>Eger sadece iki etiket varsa, matris alttaki gibi olur,</p>
<p><img alt="" src="modeval_06.png" /></p>
<p>İki etiket durumunda matristeki sayıların özel isimleri var. Her eksende
ilk hücre 1 tahmini, diğeri 0 tahmini olursa, üst sol köşedeki tahmin
gerçekten 1 olduğu ve 1 tahmin edildiği durum, buna doğru pozitif (true
positive) ismi veriliyor. 0 tahmin yapılmış ama aslında etiket 1 ise buna
yanlış negatif (false negative), 1 tahmini yapılmış ama 0 ise buna yanlış
pozitif (false positive), 0 tahmini yapılmış ve gerçekten 0 ise buna doğru
negatif (true negative) ismi veriliyor. Kısaltılmış olarak sırasıyla TP,
FN, FP, TN [1, sf. 190].</p>
<p>Doğruluk (Accuracy)</p>
<p>Üstteki değerler ile bazı özet hesaplar var, bunlardan biri
doğruluk. Formülü</p>
<p>$$ 
ACC = \frac{FP + FN}{FP + FN + TP + TN}
$$</p>
<p>Kesinlik (Precision)</p>
<p>Diyelim ki bir fotografta 12 kedi, birkac tane fare var. Bir program 8 tane
kedi var diyor, ama kedi denen objelerden sadece 5 tanesi gercekten kedi. O
zaman programin kesinligi 5/8. </p>
<p>$$ 
PRE = \frac{TP}{TP + FP}
$$</p>
<p>Hatırlama (Recall)</p>
<p>Üstteki örnekte hatırlama 5/12</p>
<p>$$ 
REC = \frac{TP}{FN + TP}
$$</p>
<p>F1 Skoru</p>
<p>Cogu zaman kesinlik ve hatirlamayi birlestirmek iyi bir fikirdir, bu bize
F1-Skoru verir, </p>
<p>$$ 
F1 = 2 \frac{PRE \cdot REC}{PRE + REC}
$$</p>
<p>Özetlemek gerekirse doğruluk tahminlerimizin ne oranda doğru olduğudur,
fakat bu ölçü eğer eğitim verisinde dengesizlik var ise başarısız olur (100
içinde 90 resim kedi ise sürekli "kedi" cevarı vermek yüzde 90 doğruluk
verir ama bu iyi bir algoritma değildir). Kesinlik ise algoritmamiz
"kedi" dediği zaman bu cevaplar içindeki doğruluk oranıdır. Yani pozitif
tahmin edebilme oranıdır. Hatırlama ise sistemin tüm kediler içinde kaçıni
bulabildiğidir, yani doğru pozitif oranı.</p>
<p>AUC</p>
<p>Eğitim verisindeki dengesizliği dikkate alarak başarı hesaplamanın bir yolu
şu: algoritmalar 0/1 tahmini yerine "1 olma olasılığı" üretirler, yani 0
ile 1 arası bir sayı. Bu olasılıkları 0/1 tahminine çevirmek kolay, bir
eşik değeri kararlaştırırız, ondan büyük olanlar 1 küçükler 0 olur; mesela
eşik değeri 0.5 olabilir. AUC hesabı için eşik değerini sürekli
değiştirerek bir döngü içinde doğru pozitif oranı, yanlış pozitif oranı
hesaplarız, bunu grafikleyince ortaya bir eğri çıkar. Bu eğri 45 derece
eğimli düz çizgi ne kadar üzerinde ise algoritmamiz o kadar başarılıdır. </p>
<p>Matthews Korelasyon Katsayısı</p>
<p>AUC kadar iyi işleyen, verideki dengesizliklere dayanıklı bir diğer ölçüt
budur. Detaylar için [4] yazısı.</p>
<p>Yanlılık-Varyans Dengesi  (Bias-Variance Trade-off)</p>
<p><img alt="" src="modeval_01.png" /></p>
<pre><code class="python">from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn import linear_model
from sklearn import ensemble
from sklearn.model_selection import ShuffleSplit
from sklearn.datasets import load_digits
import lcurve

digits = load_digits()
X, y = digits.data, digits.target

title = &quot;Naive Bayes&quot;
cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)
estimator = GaussianNB()
lcurve.plot(estimator, title, X, y, cv=cv, n_jobs=2)
plt.savefig('modeval_02.png')

title = u'SVM, RBF çekirdek (kernel), $\gamma=0.001$'
cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)
estimator = SVC(gamma=0.001)
lcurve.plot(estimator, title, X, y, cv=cv, n_jobs=2)
plt.savefig('modeval_03.png')

title = &quot;Lojistik Regresyon&quot;
cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)
estimator = linear_model.LogisticRegression()
lcurve.plot(estimator, title, X, y, ylim=(-0.1,0.1), cv=cv, n_jobs=2)
plt.savefig('modeval_04.png')

title = &quot;RandomForestClassifier&quot;
cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)
estimator = ensemble.RandomForestClassifier()
lcurve.plot(estimator, title, X, y, ylim=(-0.1,0.1), cv=cv, n_jobs=2)
plt.savefig('modeval_05.png')
</code></pre>

<p><img alt="" src="modeval_02.png" /></p>
<p><img alt="" src="modeval_03.png" /></p>
<p><img alt="" src="modeval_04.png" /></p>
<p>Kaynaklar</p>
<p>[1] Raschka, <em>Python Machine Learning</em></p>
<p>[2] Ng, Diagnosing Bias vs Variance, <a href="https://www.youtube.com/watch?v=ymg03eGEBds">https://www.youtube.com/watch?v=ymg03eGEBds</a></p>
<p>[3] Ng, Regularization and Bias Variance, <a href="https://www.youtube.com/watch?v=yzS8bl75FV0">https://www.youtube.com/watch?v=yzS8bl75FV0</a></p>
<p>[4] Bayramli, İstatistik, <em>Beklenti, Varyans, Kovaryans ve Korelasyon</em></p>