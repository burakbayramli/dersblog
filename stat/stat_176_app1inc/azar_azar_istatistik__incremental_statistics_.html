<p><a href="..">Yukarı</a></p>
<h1>Azar Azar İstatistik (Incremental Statistics)</h1>
<!DOCTYPE html>
<html>
  <head>
    <title>Azar Azar İstatistik (Incremental Statistics)
</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [["$","$"]]}
      });
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    </script>
<script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full">
</script>
</head>

<p>Eldeki bir verinin yaş, boy, kilo gibi kolonlarını özetlemenin yollarından biri
ortalama. Ortalama hesabının pek çok kütüphanede çağrısı var, mesela
<code>numpy.mean</code>, ya da Pandas <code>Series.mean</code>.</p>
<pre><code class="python">import pandas as pd
from io import StringIO

data = &quot;&quot;&quot;
Name,Height
Ali,160
Veli,170
Musa,150
Mustafa,200
Cem,180
&quot;&quot;&quot;
df = pd.read_csv(StringIO(data),sep=',')
print (df)
</code></pre>

<pre><code>      Name  Height
0      Ali     160
1     Veli     170
2     Musa     150
3  Mustafa     200
4      Cem     180
</code></pre>

<p>Ortalamayı alırsak</p>
<pre><code class="python">df['Height'].mean()
</code></pre>

<pre><code>Out[1]: 172.0
</code></pre>

<p>Matematiksl olarak eldeki $x_i$ verisi için klasik ortalama hesabı $\bar{x}$
basit, tüm değerleri topla, ve değer sayısına böl,</p>
<p>$$
\bar{x} = \frac{1}{n} \sum _{i=1}^{n} x_i
$$</p>
<p>Kod ile</p>
<pre><code class="python">print (np.array(df.Height))
mean = df.Height.sum() / len(df)
print ('ortalama',mean)
</code></pre>

<pre><code>[160 170 150 200 180]
ortalama 172.0
</code></pre>

<p>Fakat dikkat; hesabı yapmak için tüm verileri toplamak gerekti, elde çok fazla
veri olsaydı bu toplamın çok büyük rakamlara erişmesi mümkündür, bu da taşma,
veri hataları ortaya çıkartabilir.</p>
<p>Ortalamayı azar azar hesaplamak mümkün müdür acaba? O ana kadar bakılan verinin
ortalaması fazla büyümez, ayrıca paralel işletim açısından azar azar azar
işletim daha ölçeklenebilir bir yaklaşımdır. Bu tür bir hesap için matematikte
biraz değişim yapmak lazım [3].</p>
<p>Üstteki toplam formülünde ilk $n-1$ toplamını ayıralım, </p>
<p>$$
\bar{x} = \frac{1}{n} \left( \sum _{i=1}^{n-1} x_i + x_i \right)
\qquad (1)
$$</p>
<p>İki üstteki $\bar{x}$ formülü ilk $n$ verisinin ortalaması demiştik,
o zaman ilk $n-1$ verisinin ortalaması doğal olarak</p>
<p>$$
\bar{x}_{n-1}  = \frac{\sum_{i=1}^{n} x_i}{n-1} 
$$</p>
<p>Tekrar düzenlersek,</p>
<p>$$
\sum_{i=1}^{n} x_i  = (n-1) \bar{x}_{n-1}<br />
$$</p>
<p>Bu formülü (1)'e sokalım,</p>
<p>$$
\bar{x} = \bar{x}_n = \frac{1}{n} \left( (n-1) \bar{x}_{n-1} + x_n \right)
$$</p>
<p>Sag tarafi acalim,</p>
<p>$$
\bar{x}_n = \frac{n \bar{x}_{n-1} - \bar{x}_{n-1} + x_n}{n}
$$</p>
<p>$$
\bar{x}_n = \frac{n \bar{x}_{n-1}}{n} + \frac{x_n - \bar{x}_{n-1}}{n}
$$</p>
<p>Ilk terimdeki $n$'ler iptal olur,</p>
<p>$$
\bar{x}_n = \bar{x}_{n-1} + \frac{x_n - \bar{x}_{n-1}}{n}
$$</p>
<p>Yani bir sonraki ortalama hesabı için eldeki yeni veri $x_n$'den o ana kadar
elde olan ortalamayı çıkartıp $n$'ye bölüp bu sonucu önceki ortalamaya
ekleyebiliriz. Böylece sürekli daha ufak sayılarla uğraşıyoruz, patlama
olmuyor ayrıca elde sürekli bir ortalama hesabı oluyor. </p>
<pre><code class="python">barx = 160 # ilk degeri ilk ortalama olarak kullan
for n,xn in enumerate(np.array(df.Height)):
   barx = barx + (xn - barx) / (n+1)
   print (xn, barx)   
</code></pre>

<pre><code>160 160.0
170 165.0
150 160.0
200 170.0
180 172.0
</code></pre>

<p>Üstte görülen 172 değerine ulaştık.</p>
<p>Artımsal (İncremental) Varyans Hesabı (Alternatif Yöntem)</p>
<p>[1]'de gördüğümüz varyans formülünü tekrar yazarsak,</p>
<p>$$ = \sum _{i=1}^{n} y_i^2 - \frac{1}{n} \bigg( \sum _{i=1}^{n} y_i \bigg)^2 $$</p>
<p>(5) formülünü $x$ kullanarak bir daha yazalım,</p>
<p>$$ 
S = \sum _{i=1}^{n} x_i^2 - \frac{1}{n} \bigg( \sum _{i=1}^{n} x_i \bigg)^2<br />
$$</p>
<p>Bu formülü her yeni veri geldikçe eldeki mevcut varyansı "güncelleme"
amaçlı olarak tekrar düzenleyebilirdik, böylece veri üzerinden bir kez
geçmekle kalmayıp en son bakılan veriye göre en son varyansı
hesaplayabilmiş olurduk. Ortalama için mesela her yeni veri bir toplama
eklenebilir, ayrıca kaç veri noktası görüldüğü hatırlanır, ve o andaki en
son ortalama en son toplam bölü bu en son sayıdır. </p>
<p>Fakat varyans için (5)'in bir problemi var, $\sum x_i^2$ ve $(\sum x_i)^2$
sayıları uygulamalarda aşırı büyüyorlar, ve yuvarlama hataları (rounding
errors) hataları ortaya çıkmaya başlıyor. Eğer varyans küçük ise bu aşırı
büyük sayılardaki tüm basamaklar birbirini iptal eder, geriye hiçbir şey
kalmaz. Bu hatalardan uzak durmak için varyansı farklı bir artımsal
yöntemle hesaplamak istiyoruz.</p>
<p>Youngs ve Cramer'in yöntemine göre [2, sf. 69] bu hesap şöyle
yapılabilir. $T_{ij}$, $M_{ij}$ ve $S_{ij}$, veri noktaları $x_i$ $x_j$
arasındaki verileri kapsayacak şekilde sırasıyla toplam, ortalama ve verinin
karesinin toplamı olsun,</p>
<p>$$ 
T_{ij} = \sum _{k=i}^{j} x_k , \quad<br />
M_{ij} = \frac{1}{(j-1+1)}, \quad
S_{ij} = \sum _{k=i}^{j} (x_k - M_{ij})^2
$$</p>
<p>Güncelleme formülleri şunlardır, </p>
<p>$$ T_{1,j} = T_{i,j-1} + x_j$$</p>
<p>$$ S_{1,j} = S_{i,j-1} + \frac{1}{j(j-1)} (jx_j - T_{1,j})^2  $$</p>
<p>ki $T_{1,1} = x_1$ ve $S_{1,1}=0$ olacak şekilde.</p>
<p>İspat</p>
<p>$$ 
\sum _{k=1}^{j} \bigg( x_k - \frac{1}{j} T_{1j} \bigg) = 
\sum _{k=1}^{j} \bigg( x_k - \frac{1}{j} (T_{1,j-1}+x_j)  \bigg)^2
$$</p>
<p>$$ = \sum _{k=1}^{j} \bigg(
\bigg(x_k - \frac{1}{j-1}T_{1,j-1} \bigg) + 
\bigg( \frac{1}{j(j-1)} T_{1,j-1} - \frac{1}{j} x_j\bigg) 
\bigg)^2
$$</p>
<p>çünkü $\frac{1}{j} = \frac{1}{j-1}-\frac{1}{j(j-1)}$</p>
<p>$$
= \sum _{k=1}^{j-1} \bigg( x_k - \frac{1}{j-1} T_{1,j-1} \bigg)^2<br />
 \bigg( x_j - \frac{1}{j-1} T_{1,j-1} \bigg)^2 +
$$
$$
2 \sum _{k=1}^{j}  \bigg( x_k - \frac{1}{j-1} T_{1,j-1} \bigg)
\bigg( \frac{1}{j(j-1)} T_{1,j-1} - \frac{1}{j} x_j \bigg) +
$$
$$
j \bigg( \frac{1}{j(j-1)} T_{1,j-1} - \frac{1}{j} x_j \bigg) 
$$</p>
<p>$$ 
= \sum _{k=1}^{j-1} \bigg( x_k - \frac{1}{j-1} T_{1,j-1} \bigg)^2 + 
\bigg( x_j - \frac{1}{j-1} T_{1,j-1} \bigg)^2 \bigg( 1-\frac{2}{j} \bigg) + 
j \bigg( \frac{1}{j(j-1)} T_{1,j-1} - \frac{1}{j}x_j \bigg)^2
$$</p>
<p>çünkü $\sum _{k=1}^{j-1} (x_k-\frac{1}{j-1} T_{1,j-1} )=0$</p>
<p>$$ 
= S_{1,j-1}  + \bigg( x_j - \frac{1}{j-1} (T_{1j}-x_j) \bigg) ^2
\bigg( 1-\frac{2}{j}+\frac{1}{j}\bigg)
$$</p>
<p>$$ = S_{1,j-1} + \frac{1}{(j-1)^2} (jx_j - T_{1j})^2 \frac{j-1}{j} $$</p>
<p>Bu algoritma (5) algoritmasından daha stabil. Kod üzerinde görelim,</p>
<pre><code class="python">def incremental_mean_and_var(x, last_sum, last_var, j):
    new_sum = last_sum + x
    new_var = last_var + (1./(j*(j-1))) * (j*x - new_sum)**2 
    return new_sum, new_var

N = 10
arr = np.array(range(N)) # basit veri, 0..N-1 arasi sayilar
print arr
last_sum = arr[0]; last_var = 0.
for j in range(2,N+1):
    last_sum,last_var = incremental_mean_and_var(arr[j-1], last_sum, last_var, j)

print 'YC =', last_var / N, 'Standart = ', arr.var()
print last_sum, arr.sum()
</code></pre>

<pre><code>[0 1 2 3 4 5 6 7 8 9]
YC = 8.25 Standart =  8.25
45 45
</code></pre>

<p>Kaynaklar</p>
<p>[1] Bayramli, <em>Istatistik, Beklenti, Varyans, Kovaryans ve Korelasyon</em></p>
<p>[2] Weihs, <em>Foundations of Statistical Algorithms With References to R Packages</em></p>
<p>[3] Nested Software, <em>Calculating a Moving Average on Streaming Data</em>,
    <a href="https://nestedsoftware.com/2018/03/20/calculating-a-moving-average-on-streaming-data-5a7k.22879.html">https://nestedsoftware.com/2018/03/20/calculating-a-moving-average-on-streaming-data-5a7k.22879.html</a></p>